{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d1a8e6",
   "metadata": {},
   "source": [
    "# Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0df83f",
   "metadata": {},
   "source": [
    "Hello! This python script will help you clean address data for use in analysis.\n",
    "\n",
    "Currently, the script is designed to run on a pre-cleaned set of data on Eviction Filings supplied by the City of Grand Rapids. The pre-cleaned sheet should have blank rows, c/o address lines, and P.O. Boxes removed and should be filtered to include only addreses with a ZIP Code in Kent County. Additional work can be done to make sure each combination of City, State, and ZIP Code data are free of typographical errors--i did this by taking the unique values from the entire spreadsheet for City, City and State, and City and ZIP Code and made changes by hand. This kind of finnicky work saved immeasureable time on the backend.\n",
    "\n",
    "From the outset you should set aside and afternoon or even a full day (depending on your comfort with excel or another data reviewing tool) to preparing the dataset, then running it through this script, and finally reviewing missing addresses in the Final Export Document.\n",
    "\n",
    "Make sure Python 3 (any version) is installed on your device. For instructions on downloading Python, see here: https://www.dummies.com/article/technology/programming-web-design/python/how-to-install-python-on-your-computer-139548/ .\n",
    "\n",
    "To generate and set a Google Maps API key (for FREE!) follow the instructions in this link: https://yoast.com/help/generate-set-google-maps-api-key/ .\n",
    "\n",
    "The geopy code used in this notebook is adapted from code written by Aaron Zhu in \"Clean Messy Address Data Effortlessly Using Geopy and Python\" for Towards Data Science. Read the original article here: https://medium.com/towards-data-science/transform-messy-address-into-clean-data-effortlessly-using-geopy-and-python-d3f726461225 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80548c6c",
   "metadata": {},
   "source": [
    "# Upload a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e1793",
   "metadata": {},
   "source": [
    "This program accepts files in all standard excel formats (.xls, .xlsx, .csv, and others).\n",
    "\n",
    "In the first section, you will need to enter information to populate our variables. Be careful not to delete anything on the left of the equal signs (\"=\")—those are variable names and we will need them exactly as written for the code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e796f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter *SOURCE* FOLDER address from file directory in quotation marks--\n",
    "## the folder that holds your file\n",
    "## make sure all slashes are BACKslashes (\"\\\") and \n",
    "## that there are 2 backslashes after the drive (e.g., \"C:\\\\\")\n",
    "folder_source = \"C:\\\\YOUR_DIRECTORY\\YOUR_FOLDER\"\n",
    "\n",
    "# Enter the FILE NAME *with EXTENSION* in quotation marks (e.g., \"evicitions_file.xlsx\")\n",
    "## this will not work without the extension at the end, so verify it is added\n",
    "file = \"YOUR_FILE.xlsx\"\n",
    "\n",
    "# If you have more than 1 sheet in your target file, type the name \n",
    "## of the sheet you would like to use from the workbook in quotation marks\n",
    "## if there is no sheet, just enter blank quotation marks (e.g., \"\")\n",
    "sheet = \"SHEET_NAME\"\n",
    "\n",
    "# Enter the COLUMN NAMES that hold Street Address, City, State, and ZIP Code from your dataset\n",
    "## so we can match the correct columns later\n",
    "street = \"STREET_ADDRESS\"\n",
    "city = \"CITY\"\n",
    "state = \"STATE\"\n",
    "zip_code = \"ZIP_CODE\"\n",
    "\n",
    "# Enter *SAVE* FOLDER address from file directory in quotation marks--\n",
    "## the folder into which you want a the cleaned data saved\n",
    "## make sure all slashes are BACKslashes (\"\\\") and \n",
    "## that there are 2 backslashes after the drive (e.g., \"C:\\\\\")\n",
    "## set equal to folder_source by default\n",
    "folder_save = folder_source\n",
    "\n",
    "# Enter your key for accessing the Google Maps API\n",
    "google_cloud_key = \"YOUR_KEY_HERE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db67b86",
   "metadata": {},
   "source": [
    "In the next section, we will !pip install the pandas library from PyPI. If you already have this installed, skip to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86070968",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4ea73",
   "metadata": {},
   "source": [
    "If you successfully installed pandas or you have it previously installed, move on to the next code section.\n",
    "\n",
    "In this section we will load pandas to our environment and create and open our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "workbook = folder_source + \"\\\\\" + file\n",
    "if workbook[-4:-1] == \".cs\":\n",
    "    addressesDF = pd.read_csv(workbook)\n",
    "else:\n",
    "    addressesDF = pd.read_excel(workbook,sheet_name = sheet,engine = \"openpyxl\")\n",
    "\n",
    "df = addressesDF \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25714d9d",
   "metadata": {},
   "source": [
    "##### Be sure to check that the result from the previous code has 7 columns and the same number of rows as your data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4baec82",
   "metadata": {},
   "source": [
    "## Formatting as List and Cleaning\n",
    "\n",
    "Next we will take a unique list of addresses from the dataset to save some compute when we pass the information to the Google Maps API. Every 1000 addresses processed costs $5 and it adds up fast. We want to stay well below our free monthly limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADDRESS'] = df[street] + \", \" + df[city] + \", \" + df[state] + ' ' + df[zip_code].astype(str)\n",
    "df_unique = pd.DataFrame(pd.unique(df['ADDRESS']),columns = ['Old_Addresses']).dropna()\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a449b4",
   "metadata": {},
   "source": [
    "Check to see that your results look right. If not, you may need to adjust your variables at the top of the notebook or adjust something in the source file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cddb6c",
   "metadata": {},
   "source": [
    "## Installing GeoPy and Pinging the API\n",
    "\n",
    "In the next section, we will !pip install the geopy and re library from PyPI. If you already have these installed, skip to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy\n",
    "!pip install re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086addf1",
   "metadata": {},
   "source": [
    "If you successfully installed pandas or you have it previously installed, move on to the next code section.\n",
    "\n",
    "In this section we will load geopy, make our connection to the Google Maps API, pass our data to the API, and save information from each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad504fb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import geopy\n",
    "import re\n",
    "\n",
    "from geopy.geocoders import GoogleV3\n",
    "geolocator = GoogleV3(api_key=google_cloud_key)\n",
    "\n",
    "def extract_clean_address(address):\n",
    "    try:\n",
    "        location = geolocator.geocode(address)\n",
    "        return [location.address, location.latitude, location.longitude]\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "df_unique['add_lat_long'] = df_unique.apply(lambda x: extract_clean_address(x['Old_Addresses']), axis = 1)    \n",
    "df_unique['Address_F'] = df_unique.apply(lambda x: x['add_lat_long'][0] if x['add_lat_long'] != '' else '', axis = 1)\n",
    "df_unique['Latitude_F'] = df_unique.apply(lambda x: x['add_lat_long'][1] if x['add_lat_long'] != '' else '', axis = 1)\n",
    "df_unique['Longitude_F'] = df_unique.apply(lambda x: x['add_lat_long'][2] if x['add_lat_long'] != '' else '', axis = 1)\n",
    "df_unique.drop(columns = ['add_lat_long'],inplace = True)\n",
    "\n",
    "print(df_unique)\n",
    "\n",
    "csvFile = folder_save + \"\\\\\" + re.sub(\"\\..*\",\"\",file) + \"_uniqAddressesCl.csv\"\n",
    "pd.DataFrame.to_csv(df_unique, path_or_buf = csvFile, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a53463",
   "metadata": {},
   "source": [
    "The previous code module may take a few minutes. Once finished, I recommend opening the file containing the unique old addresses with results from the api for each. The file should be called \"\\[file name\\]\\_uniqAddressesCl.csv\" and located in the file_save folder. Especially check for blanks in Address_F, Latitude_F, and Longitude_F. Blanks signify that the address in questions was not accepted by the algorithm. If you have time and some free compute left from Google Cloud Platform, you may want to try the following. Otherwise skip to the next header and continue from there.\n",
    "\n",
    "> As an aside—and only if your blanks count greater than 1% of the dataset—one could subset these addresses and paste them to a new file in order to review them. If you can use your human skills to clean them at all and then replace the original in the source file, you can rerun this notebook from the start to see if your edits lead to better results. But, you only want to this once, so be definitive in your changes. Re-running more than once may cause you to use up your free compute from Google Cloud Platform and force you to pay out of pocket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af969f",
   "metadata": {},
   "source": [
    "## Merging New Data and Old Data; Final Check\n",
    "\n",
    "Next, we will left join the columns Address_F, Latitude_F, and Longitude_F to all rows in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.merge(\n",
    "                df_unique,\n",
    "                how = \"left\",\n",
    "                left_on = 'ADDRESS',\n",
    "                right_on = 'Old_Addresses'\n",
    "            ).drop(columns = ['Old_Addresses'])\n",
    "\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c19f9f",
   "metadata": {},
   "source": [
    "Check the printed results for errors. This is only a cursory check of 10 rows, but problems should be clearly evident: blank cells, incorrect matches, etc.\n",
    "\n",
    "If satisfied, proceed to the next code block to save the file as a .xlsx workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalFile = folder_save + \"\\\\\" + re.sub(\"\\..*\",\"\",file) + \"_clFinal.csv\"\n",
    "pd.DataFrame.to_csv(df_final, path_or_buf = finalFile, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9cab1",
   "metadata": {},
   "source": [
    "## Congrats!\n",
    "\n",
    "That is it! All you have to now is open your file and check your data. If you have issues, questions, concerns, or reccomendations, email me at hileevanw@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
